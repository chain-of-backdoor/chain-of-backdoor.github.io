<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Chain of Backdoor Attacks for Code-Driven Embodied Intelligence</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Chain of Backdoor Attacks for Code-Driven Embodied Intelligence</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <!-- <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span> -->
                  <span class="author-block">Anonymous Authors</span>
                  </div>

                  <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div> -->

                  <div class="column has-text-centered">
                    <div class="publication-links">
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have revolutionized the programming and development of embodied intelligence. In this paradigm, LLMs translate complex tasks described in abstract language into a sequence of code snippets. The embodied agent subsequently interacts with the environment to solve these tasks, with the execution logic guided by the programs and the orchestration of operation calls (\eg, perception modules). However, exploiting untrusted third-party LLMs poses considerable security risks. This paper introduces BackdoorChain, which for the first time identifies a severe chain of backdoor threats in this practical scenario. By presenting a few shots of poisoned demonstrations, adversaries can clandestinely infect a black-box LLM, prompting it to generate programs with backdoor defects. These malicious programs, supplied by LLMs to downstream users, will be activated and compromise the reliability of the operational agent when specific visual triggers appear. Originating from a few shots of stealthy demonstrations, our attack progresses from LLM to the generated code until infiltrating the intelligent system, thus establishing a chain of backdoors that could have serious consequences for millions of downstream embodied agents. To achieve the goal, we employ an additional LLM for poisoned demonstration prompt generation and treat the optimization process as a two-player game between the discriminator and generator LLMs, where the optimized poisoned prompts fed to the generator could output programs with accurate defects that are realistic enough output to fool the discriminator. To comprehensively explore the potential risks, we broaden the attack and devise five program defects attacking modes compromising the key aspects of confidentiality, integrity, and availability of the embodied agents. To validate the effectiveness, we conducted extensive experiments on a range of tasks including robot planning, robot manipulation, and compositional visual reasoning. Additionally, we showcase the potential of our approach and successfully attack real-world autonomous driving systems. This paper aims to raise awareness of the potential threats of backdoors for embodied intelligence in practical LLM usage scenarios involving code.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="container is-max-desktop">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Your image here -->
      <img src="static/images/frontpage-2.png" alt="MY ALT TEXT" autoplay controls muted loop height="100%"/>
        <h2 class="subtitle has-text-centered">
          Illustration of the chain of backdoor attacks to code-driven embodied agents. We propose BackdoorChain to induce LLMs to generate malicious programs with backdoors, which can be activated by visual triggers resulting in targeted behaviors for downstream agents.
        </h2>
  </div>
</div>
</section>
<!-- End image carousel -->

<!-- Teaser video-->
<section class="hero teaser is-light">
  <br/>
  <br/>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/CCS_version1.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Video recordings mentioned in Section 6. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
